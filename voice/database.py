import pickle
import os
import datetime
import numpy as np
import speech_recognition as sr
from voice.recognition import extract_voice_features, record_audio_sample, recognize_speech
from voice.synthesis import speak_async
from utils.config import VOICE_DATABASE_FILE
from utils.helpers import add_to_conversation_history

voice_database = {}


def load_voice_database():
    global voice_database
    if os.path.exists(VOICE_DATABASE_FILE):
        try:
            with open(VOICE_DATABASE_FILE, 'rb') as f:
                voice_database = pickle.load(f)
            print(f"‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(voice_database)} –≥–æ–ª–æ—Å–æ–≤–∏—Ö –ø—Ä–æ—Ñ—ñ–ª—ñ–≤")
            for name in voice_database.keys():
                print(f"   üë§ {name}")
        except Exception as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –≥–æ–ª–æ—Å–æ–≤–æ—ó –±–∞–∑–∏: {e}")
            voice_database = {}
    else:
        print("üìÅ –§–∞–π–ª –≥–æ–ª–æ—Å–æ–≤–æ—ó –±–∞–∑–∏ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ, —Å—Ç–≤–æ—Ä—é –Ω–æ–≤—É")
        voice_database = {}
    return voice_database


def save_voice_database():
    try:
        with open(VOICE_DATABASE_FILE, 'wb') as f:
            pickle.dump(voice_database, f)
        print(f"‚úÖ –ì–æ–ª–æ—Å–æ–≤–∞ –±–∞–∑–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–∞ ({len(voice_database)} –ø—Ä–æ—Ñ—ñ–ª—ñ–≤)")
        return True
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≥–æ–ª–æ—Å–æ–≤–æ—ó –±–∞–∑–∏: {e}")
        return False


def recognize_voice(audio_data):
    global voice_database
    if not voice_database:
        print("üîç –ë–∞–∑–∞ –≥–æ–ª–æ—Å—ñ–≤ –ø–æ—Ä–æ–∂–Ω—è - –Ω–µ–º–∞—î –ø—Ä–æ—Ñ—ñ–ª—ñ–≤ –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è")
        return None

    features = extract_voice_features(audio_data)
    if features is None:
        print("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ –æ—Å–æ–±–ª–∏–≤–æ—Å—Ç—ñ –≥–æ–ª–æ—Å—É")
        return None

    best_match = None
    best_score = 0
    print(f"üîç –ü–µ—Ä–µ–≤—ñ—Ä—è—é {len(voice_database)} –≥–æ–ª–æ—Å–æ–≤–∏—Ö –ø—Ä–æ—Ñ—ñ–ª—ñ–≤...")

    for name, voice_profile in voice_database.items():
        try:
            stored_features = voice_profile['features']
            distance = np.linalg.norm(features - stored_features)
            similarity = 1 / (1 + distance)
            print(f"   {name}: —Å—Ö–æ–∂—ñ—Å—Ç—å {similarity:.3f}")

            if similarity > best_score and similarity > 0.6:
                best_score = similarity
                best_match = name
        except Exception as e:
            print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∑ {name}: {e}")
            continue

    if best_match:
        print(f"‚úÖ –ù–ê–ô–ö–†–ê–©–ò–ô –ó–ë–Ü–ì: '{best_match}' (—Å—Ö–æ–∂—ñ—Å—Ç—å: {best_score:.3f})")
    else:
        print("‚ùå –ó–ë–Ü–ì–Ü–í –ù–ï –ó–ù–ê–ô–î–ï–ù–û (—Å—Ö–æ–∂—ñ—Å—Ç—å < 0.6)")

    return best_match


def learn_new_voice():
    global voice_database
    print("\nüéì –ü–û–ß–ê–¢–û–ö –ù–ê–í–ß–ê–ù–ù–Ø –ù–û–í–û–ì–û –ì–û–õ–û–°–£")
    print("üó£Ô∏è –°–∫–∞–∂—ñ—Ç—å –≤–∞—à–µ —ñ–º'—è...")
    speak_async("–î–∞–≤–∞–π—Ç–µ –Ω–∞–≤—á–∏–º–æ—Å—è –≤–∞—à–æ–º—É –≥–æ–ª–æ—Å—É. –°–∫–∞–∂—ñ—Ç—å –≤–∞—à–µ —ñ–º'—è.")

    name = recognize_speech(timeout=10)
    if not name:
        print("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è —Ä–æ–∑–ø—ñ–∑–Ω–∞—Ç–∏ —ñ–º'—è")
        speak_async("–ù–µ –≤–¥–∞–ª–æ—Å—è —Ä–æ–∑–ø—ñ–∑–Ω–∞—Ç–∏ —ñ–º'—è. –°–ø—Ä–æ–±—É–π—Ç–µ —â–µ —Ä–∞–∑.")
        return False

    name = name.strip().capitalize()
    print(f"üë§ –Ü–ú'–Ø –î–õ–Ø –ù–ê–í–ß–ê–ù–ù–Ø: '{name}'")
    speak_async(f"–ß—É–¥–æ–≤–æ, {name}! –¢–µ–ø–µ—Ä –±—É–¥—å –ª–∞—Å–∫–∞, —Å–∫–∞–∂—ñ—Ç—å —Ñ—Ä–∞–∑—É –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è.")

    samples = []
    successful_samples = 0

    for i in range(3):
        print(f"\nüìù –ó–†–ê–ó–û–ö {i + 1} –ó 3...")
        speak_async(f"–ó—Ä–∞–∑–æ–∫ {i + 1} –∑ 3. –°–∫–∞–∂—ñ—Ç—å —Ñ—Ä–∞–∑—É.")

        audio_data = record_audio_sample(timeout=5)
        if audio_data:
            features = extract_voice_features(audio_data)
            if features is not None:
                samples.append(features)
                successful_samples += 1
                print(f"‚úÖ –ó—Ä–∞–∑–æ–∫ {i + 1} —É—Å–ø—ñ—à–Ω–æ –∑–∞–ø–∏—Å–∞–Ω–∏–π")
                speak_async("–î–æ–±—Ä–µ, –∑—Ä–æ–∑—É–º—ñ–≤.")
            else:
                print(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –æ–±—Ä–æ–±–∏—Ç–∏ –∞—É–¥—ñ–æ –∑—Ä–∞–∑–∫–∞ {i + 1}")
                speak_async("–ù–µ –≤–¥–∞–ª–æ—Å—è –æ–±—Ä–æ–±–∏—Ç–∏ –∞—É–¥—ñ–æ. –°–ø—Ä–æ–±—É–π—Ç–µ —â–µ —Ä–∞–∑.")
        else:
            print(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–ø–∏—Å–∞—Ç–∏ –∞—É–¥—ñ–æ –∑—Ä–∞–∑–∫–∞ {i + 1}")
            speak_async("–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–ø–∏—Å–∞—Ç–∏ –∞—É–¥—ñ–æ. –°–ø—Ä–æ–±—É–π—Ç–µ —â–µ —Ä–∞–∑.")

        time.sleep(1)

    print(f"\nüìä –ü–Ü–î–°–£–ú–û–ö: {successful_samples} –∑ 3 –∑—Ä–∞–∑–∫—ñ–≤ —É—Å–ø—ñ—à–Ω–∏—Ö")

    if successful_samples >= 2:
        avg_features = np.mean(samples, axis=0)
        voice_database[name] = {
            'features': avg_features,
            'samples_count': successful_samples,
            'learned_date': datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }

        if save_voice_database():
            print(f"‚úÖ –ì–û–õ–û–° '{name}' –£–°–ü–Ü–®–ù–û –ù–ê–í–ß–ï–ù–ò–ô!")
            print(f"   üìÖ –î–∞—Ç–∞ –Ω–∞–≤—á–∞–Ω–Ω—è: {voice_database[name]['learned_date']}")
            print(f"   üìù –ó—Ä–∞–∑–∫—ñ–≤: {successful_samples}")
            speak_async(f"–ß—É–¥–æ–≤–æ! –Ø –∑–∞–ø–∞–º'—è—Ç–∞–≤ –≤–∞—à –≥–æ–ª–æ—Å, {name}. –¢–µ–ø–µ—Ä —è –º–æ–∂—É —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞—Ç–∏ –≤–∞—Å.")
            return True
        else:
            print("‚ùå –ö–†–ò–¢–ò–ß–ù–ê –ü–û–ú–ò–õ–ö–ê: –Ω–µ –≤–¥–∞–ª–æ—Å—è –∑–±–µ—Ä–µ–≥—Ç–∏ –≥–æ–ª–æ—Å–æ–≤–∏–π –ø—Ä–æ—Ñ—ñ–ª—å")
            speak_async("–ü–æ–º–∏–ª–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –ø—Ä–æ—Ñ—ñ–ª—é. –°–ø—Ä–æ–±—É–π—Ç–µ –ø—ñ–∑–Ω—ñ—à–µ.")
            return False
    else:
        print("‚ùå –ù–ï–í–î–ê–õ–ï –ù–ê–í–ß–ê–ù–ù–Ø: –Ω–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ —è–∫—ñ—Å–Ω–∏—Ö –∑—Ä–∞–∑–∫—ñ–≤ –≥–æ–ª–æ—Å—É")
        speak_async("–ù–µ –≤–¥–∞–ª–æ—Å—è –∑—ñ–±—Ä–∞—Ç–∏ –¥–æ—Å—Ç–∞—Ç–Ω—å–æ —è–∫—ñ—Å–Ω–∏—Ö –∑—Ä–∞–∑–∫—ñ–≤ –≥–æ–ª–æ—Å—É. –°–ø—Ä–æ–±—É–π—Ç–µ —â–µ —Ä–∞–∑.")
        return False